# Model Security using Langkit on HuggingFace Models

## Introduction

This repository contains a Colab notebook that demonstrates how to check security on Large Lanuage Models using Langkit on HuggingFace models. The notebook provides a step-by-step guide on how to implement security measures for your models.

## Getting Started

### Prerequisites

- Python 3.7 or later
- Jupyter Notebook
- HuggingFace Transformers
- Langkit

### Installation

1. Clone the repository:

2. ```bash
   git clone https://github.com/mrudulmamtani/ModelSec-with-Langkit.git
   ```
3. Install the required packages:
   ```bash
     pip install -r requirements.txt
   ```


## Usage

Open the Jupyter notebook (`LangKit_on_HuggingFace_Models.ipynb`) and follow the instructions in the notebook.

## Contributing

Contributions are welcome! Please read our Contributing Guide and our Code of Conduct for details on our code of conduct and the process for submitting pull requests to us.

## License

This project is licensed under the MIT License - see the LICENSE.md file for details.

## Acknowledgments

- HuggingFace for their amazing Transformers library
- Langkit for their robust language toolkit


